{
  "title": "04-Hive-0106-Hive01:基本命令和分区分桶和排序等",
  "cells": [
    {
      "type": "markdown",
      "data": "## Hive的使用01"
    },
    {
      "type": "markdown",
      "data": "*注意：hive默认是不支持行级操作的哈*\n\n* 上面说的好像也不对，可以执行insert操作，会转化成mr\n* 查过资料，确定hive默认支持insert，会转换成mr插入。但是不支持update和delete操作，但是可以通过更改配置文件增减update和delete的支持\n\n > insert into stu(id,name,age) values (1, 'tom', 12);\n \n * 如果在创建表的时候没有指定分隔符，应该是不能通过load方式加载文件的\n \n \n* 07，复制表，这个和sql是一样的\n  create table t4_copy as select * from t4;//结构和数据都复制\n\n  create table t4_struc_copy like t4;//只复制结构"
    },
    {
      "type": "markdown",
      "data": "\n## 1，创建表\n*Hive中表有两种，一种是托管表，默认就是托管表，另外一种是外部表。*\n* 01，托管表在删除表的时候， 数据也会被删除\n* 02, 外部表在删除表的时候， 数据不会被删除\n"
    },
    {
      "type": "markdown",
      "data": "## 2，Hive命令\n*  01, 创建表，默认方式 :\n    CREATE TABLE IF NOT EXISTS t1(id int,name string,age int) COMMENT '这是注释'; \n\n*  02, 创建表，默认方式加强版:  \n    CREATE TABLE IF NOT EXISTS t2(id int,name string,age int) COMMENT '这是注释' ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE;\n\n    > CREATE external TABLE IF NOT EXISTS t2(id int,name string,age int) COMMENT '这是注释' ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE;\n\n\n* 指定分隔符和不指定分隔符：![IMAGE](quiver-image-url/3786A1A79C05AB2590D9D41D737BB50A.jpg =414x59)\n\n* 03，查看表的具体信息\n    desc t1;\n    desc formatted t1;\n\n* 04, 加载本地文件到hive表，另外需要注意：如果覆盖，之前的数据会全部删除哦， 这个其实是上传本地文件到hive的表目录下\n    > load data local inpath '/root/share/customers.txt' [overwrite] into table t2;//注意：如果文件中有分隔符，创建表的时候也必须要添加分隔符限制\n\n* 05, 加载hdfs上的文件到hive表， 这个其实是把hdfs原目录的文件移动到hive指定的表的目录下\n  > load data inpath '/user/root/customer.txt' into table t3;\n\n* 06, 创建外部表,\n    > CREATE external TABLE IF NOT EXISTS t4(id int,name string,age int) COMMENT '这是注释' ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE;\n    > 加载数据也是和托管表一样，也是上传或者移动数据，但是只是删除数据的时候，文件不会被删除\n\n* 07，复制表，这个和sql是一样的\n  create table t4_copy as select * from t4;//结构和数据都复制\n\n  create table t4_struc_copy like t4;//只复制结构\n  \n* 08，count()查询要转成mr\n\t>select count(*) from t2 ;\n\n* 09, 启用/禁用表，现在貌似不管用\n  \n  ALTER TABLE t2 ENABLE NO_DROP;\t//不允许删除\n\t$hive>ALTER TABLE t2 DISABLE NO_DROP;\t//允许删除\n\n* 10, 创建分区表.\n  分区表,优化手段之一，从目录的层面控制搜索数据的范围。\n  * 首先创建分区表\n    > CREATE TABLE t5(id int,name string,age int) PARTITIONED BY (Year INT, Month INT) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' ;\n\n  * 然后添加分区，其实就是创建目录\n    > alter table t5 add partition (year=2017, month=12);\n    > alter table t5 add partition (year=2018, month=01) partition(year=2018, month=02);\n  * 然后可以查看分区\n    > show partitions t5;\n \n  * 如果有添加错误的分区或者不需要的分区，可以删除\n    > alter table t5 drop partition (year=2019, month=23);\n\n  * 加载数据到分区，需要指定分区哦\n    > load data local inpath '/root/share/customers.txt' into table t5 partition (year=2018, month=02); # 注意：这里是有一个问题的，month=02，在创建文件夹的时候其实是名字为2的文件夹，0是不会添加在里面的\n\n  * 其实还有动态分区，参考 `94/350 [O'REILLY]Programming Hive`\n    > 动态分区，后面填坑\n    ![IMAGE](quiver-image-url/6C7B6932AE20AD7A2CC5F19FD22C2300.jpg =700x652)\n\n* 11, 桶表\n  *桶表其实就是按文件进行划分，比如说以id值做参考创建三个桶，那么会通过hash值均分到三个文件中*\n\n  * 创建桶表t6\n    create table t6 (id int, name string, age int) clustered by (id) into 3 buckets row format delimited fields terminated by ',';\n\n  * 插入数据, 这里需要注意一点：如果用load加载数据到桶表，是不能实现分桶操作的。可以通过先加载数据到其他表，再复制到桶表中是ok的，我们这里把分区表t5中的数据复制到t6中去, 如果成功后会在t6表中到文件夹中多三个文件，也就是三个桶\n    insert into t6 select id, name, age from t5;//会转mr\n\n  * 上面说的好像也不对，如下图，桶表应该也能加载数据，但是要设置属性，不过好像load方式也不推荐，我们这里就不尝试了\n    * ![IMAGE](quiver-image-url/4A0CEC94195DA641B247FBD98AEC00AC.jpg =853x433)\n    * ![IMAGE](quiver-image-url/3C7F6D994DAD4F55BAD7B94E96EEDA96.jpg =585x328)\n\n  //桶表的数量如何设置?\n\t//评估数据量，保证每个桶的数据量block的2倍大小。一般也就是256M\n\t\n* 12，连接查询\n\t  \n  * 首先创建表\n\t    CREATE TABLE customers(id int,name string,age int) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' ;\n\t    CREATE TABLE orders(id int,orderno string,price float,cid int) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' ;\n  \n  * 然后加载数据到表\n    load data local inpath '/root/share/customers.txt' into table customers;\n    load data local inpath '/root/share/orders.txt' into table orders;\n\n\n  * 通过正常到sql连接语句即可\n    * 内连接\n      > select a.\\*, b.\\* from customers as a, orders as b where a.id = b.cid;\n    * 左外连接,优先显示左边，右边没有匹配到也会显示左边的数据\n      > select a.\\*, b.\\* from customers as a left outer join orders as b on a.id = b.cid;\n    * 右外连接,优先显示右边，左边没有匹配到也会显示右边数据\n      > select a.\\*, b.\\* from customers as a right outer join orders as b on a.id = b.cid;\n\n    * 全外连接，注意这个mysql中是没有这个语法的哈，只是hive中有，可以同时查到没有订单的顾客和没有顾客的订单\n      > select a.\\*, b.\\* from customers as a full outer join orders as b on a.id = b.cid;\n      \n* 13， 数据的导入导出\n\n  * 导出表结构+数据。\n    > EXPORT TABLE customers TO '/user/centos/data';\t\n  \n  * 导出的数据是一个文件夹，该文件夹下有一个_metadata文件，是元数据，记录表的结构，字段，分隔符等相关信息。还有一个/data/目录，下面放的是数据文件，如果这张表你是加载是文件上去的，那么导出来的文件和上传的那个文件是一摸一样的哈\n\n\n* 14, order:全排序， mr排序\n  *书里说这个排序用的方法就是设置了一个reducer，这么夸张吗*\n  > select * from orders order by id desc ;\n\n\n* 15, sort:部分排序。\n  *这个就是部分排序，如果设置了reducer个数是1，那么就等于order排序，也就是全排序了*\n\n   > select * from orders sort by id desc ;\n   \n   * 可以设置reducer的个数\n    > set mapred.reduce.tasks=2;//这个设置reduce的个数\n    > set mapreduce.job.reduces=0 //这个设置好像无效\n    > set hive.exec.reducers.max=0//这个可以限制\n   \n    * ![IMAGE](quiver-image-url/94FBC882E0972A3BDA47A3D68E6C59B3.jpg =433x203)\n    * 上图说明：两个reduce，8，5，4，3，1有序，是第一个，9，7，6，2有序是第二个\n\n\n* 16，DISTRIBUTE BY，mapper端的分区操作,需要放在sort之前，因为排序之前需要确定哪些数据进入哪个reducer，要不然怎么排序.....这个作用不是特别懂， 说是类似于mysql的group by， 大概意思应该是group by的字段会进入到一个reduce，然后配合使用sort就可以实现分组后排序。比如下面，根据用户id分组后，根据订单id排序。\n* \n  > select cid , orderno, oid from orders distribute by cid sort by oid ;\n\n* 17， cluster by ===>  distribute by cid sort by cid\n*意思是如果DISTRIBUTE BY和sort by需要操作同一个字段，可以直接用cluster by，这个就是简写。当然如果向上面那样cid分组，oid排序，是不能用这个哈*\n  > select cid , orderno, cid from orders cluster by cid ;\n\n![IMAGE](quiver-image-url/44D3E56709240486C15F2C70D794105A.jpg =819x454)\n"
    },
    {
      "type": "markdown",
      "data": "\n"
    }
  ]
}
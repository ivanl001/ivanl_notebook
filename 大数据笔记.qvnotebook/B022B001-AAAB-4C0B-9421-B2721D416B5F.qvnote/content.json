{
  "title": "15-eshop项目-0309-cron实现nginx日志滚动",
  "cells": [
    {
      "type": "markdown",
      "data": "* "
    },
    {
      "type": "markdown",
      "data": "### 1, 先写脚本把nginx的日志滚动性的发到flume监听的目录中\n```shell\n#!/bin/bash\n\n# 时间,到分钟,这个可以根据我们的定时任务来决定，比如说一分钟拷贝一\n次，就可以到分钟，一个小时拷贝一次，到小时也是ok的\ndataformat=`date +%Y-%m-%d-%H-%M`\n\n# 把原始的日志文件定时拷贝到新文件中\ncp /data/nginx/access.log /data/nginx/access_$dataformat.log\n\n# 获取当前的主机名，因为后面flume会同时收集多个服务器文件，所以需要用主机名识别一下\nhost=`hostname`\n\n\n# 通过流处理在每行的头部加上服务器名字,流处理器不太懂，后面需要学习一下\nsed -i 's/^/'${host}',&/g' /data/nginx/access_$dataformat.log\n\n# 计算拷贝文件的行数，方便从原始的access.log文件中删除\nlines=`wc -l < /data/nginx/access_$dataformat.log`\n\n#move access-xxx.log flume's spooldir, 先把拷贝后的文件转移到flume\n搜集的文件夹中去，方便flume进行搜集\nmv /data/nginx/access_$dataformat.log /data/flume/estore_logs\n\n\n#delete rows，通过流处理删除已经拷贝的那些行\nsed -i '1,'${lines}'d' /data/nginx/access.log\n\n\n#reboot nginx , otherwise log can not roll.\n# nginx杀死后会自动重启\nkill -USR1 `cat /var/run/nginx.pid`\n# 需要更新一下nginx，不然的话nginx不能进行写入\n#nginx -s reload\n```"
    },
    {
      "type": "markdown",
      "data": "### 2, 执行定时任务crontab\n```shell\n# 每隔一个小时执行一次\n*/60 * * * * prepareLog.sh\n```"
    },
    {
      "type": "markdown",
      "data": "### 3, 大功告成！"
    }
  ]
}
{
  "title": "04-Hive-0201-Hive02:动态分区和事务支持",
  "cells": [
    {
      "type": "markdown",
      "data": "## 1，Hive的使用02"
    },
    {
      "type": "markdown",
      "data": "* select * from TBLS \\G;  😁\\G是行转列，在查看的时候比较方便一些，技能+1；"
    },
    {
      "type": "markdown",
      "data": "\n### 01，自动分区(动态分区)：\n  *在加入的时候根据加入数据的字段自动分区，而不必把分区数据定死。如下，演示一下动态分区*\n\n  * 首先创建一个有年份和月份的表，用作数据插入的元数据\n    > create table t7 (id int , name string , age int, year string, month string);\n  \n  * 然后插入两条不同年份或月份的数据吧\n    > insert into t7 (id, name, age, year, month) values (1, \"ivanl0000\", 10, 2015, 12);\n  \n    > insert into t7 (id, name, age, year, month) values (2, \"ivanl111111\", 15, 2016, 11);\n  \n  * 然后把上面表中的两条数据插入到我们之前建的分区表t5中去，因为并没有开启动态分区，会报错：\n    > insert into t5 partition (year, month) select id, name, age, year, month from t7;\n  \n  * 上面的插入会报错, 默认严格模式，严格模式在插入时候必须要指定一个静态分区，我们关闭这个严格模式即可：\n    > FAILED: SemanticException [Error 10096]: Dynamic partition strict mode requires at least one static partition column. To turn this off set hive.exec.dynamic.partition.mode=nonstrict\n  \n  * 根据提示可以知道需要设置分区模式为非严格模式\n    > set hive.exec.dynamic.partition.mode=nonstrict\n  \n  * 重新插入发现ok了\n  \n  "
    },
    {
      "type": "markdown",
      "data": "### 02，hive的事务\n\n*只有用事务才能支持行级操作，比如更新，删除某一行等等*\n \n  * 使用事务必须要先配置如下：\n    ```properties\n    1.所有事务自动提交。\n    2.只支持orc格式。\n    3.使用bucket表。\n    4.配置hive参数，使其支持事务。\n  \t\n  \t###### 注意：下面如果只是在命令行设置而不改变配置文件，那么只会单次有效哈\n  \t\n    SET hive.support.concurrency = true;\t\t\t\t\n    SET hive.enforce.bucketing = true;\n    //上面会报错Query returned non-zero code: 1, cause: hive configuration hive.enforce.bucketing does not exists.，先忽略\n    SET hive.exec.dynamic.partition.mode = nonstrict;\t\n    SET hive.txn.manager = org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;\n    SET hive.compactor.initiator.on = true;\n    SET hive.compactor.worker.threads = 1;\n    ```\n  \n  * 显示当前运行的事务\n    > show transactions;\n  \n  * 更新操作(默认使用事务自动提交)\n    > update t2 set name = 'ivanl001' where id = 2;\n    * 其实会报错：FAILED: SemanticException [Error 10297]: Attempt to do update or delete on table imdb.t2 that does not use an AcidOutputFormat or is not bucketed， 因为表不是桶表\n    \n  * 所以我们这里需要重新建立一个桶表,但是跟之前不一样，这里需要额外设置存储格式为orc\n    > create table t8 (id int, name string, age int) clustered by (id) into 3 buckets row format delimited fields terminated by ',' stored as orc;\n\n  * 因为load是没办法完成分桶操作的， 所以还是和之前一样， 直接从t5表中拷贝过来\n    > insert into t8 select id, name, age from t5;\n\n  * 执行更新操作\n    > update t8 set name = \"ivanl001\" where id = 3;\n    * 不过还是会报错： FAILED: SemanticException [Error 10122]: Bucketized tables do not support INSERT INTO: Table: imdb.t8\n    * 最后发现是有一个属性需要在创建表的时候指定，所以我们重新创建表t9, 具体属性如下\n  \n  * 重新创建新表t9:需要设置属性TBLPROPERTIES, 注意：单词别写错了，吃过亏\n    > create table t9 (id int, name string, age int) clustered by (id) into 3 buckets row format delimited fields terminated by ',' stored as orc tblproperties  ('transactional'='true');\n \n  * 然后重新把数据拷贝过来\n    > insert into t9 select id, name, age from t5;\n\n  * 执行更新操作\n    > update t9 set name = \"ivanl001\" where id = 3;\n\n  * 这次就ok啦。嘿嘿😁"
    },
    {
      "type": "markdown",
      "data": ""
    },
    {
      "type": "markdown",
      "data": "## 03，group by\n*注意：分组聚合的话，select的信息只能是组的信息，而不能是每一条的信息了， 比如说按照用户分组，那么能查出来的肯定是这个用户的比如说订单数量， 订单总金额等等，而不能是具体订单等信息*\n  * select id, name, price , cid from orders group by cid;\n    * 所以这个会直接报错：FAILED: SemanticException [Error 10025]: Line 1:7 Expression not in GROUP BY key 'id'\n    \n  * select count(*), sum(price), cid from orders group by cid;//这样是可以的\n  \n  * select count(*), sum(price) as s, cid from orders group by cid having cid > 30;//分组之后再进行条件筛选"
    },
    {
      "type": "markdown",
      "data": ""
    },
    {
      "type": "markdown",
      "data": "\n\n\n\n\n\n\n\n\n\n\n\n\n#ddd"
    }
  ]
}
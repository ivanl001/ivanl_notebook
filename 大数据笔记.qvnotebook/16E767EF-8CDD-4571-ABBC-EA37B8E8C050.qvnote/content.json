{
  "title": "13-Spark-0301-Spark源码学习，RDD等",
  "cells": [
    {
      "type": "markdown",
      "data": "三级调度：\n* DAGScheduler\n  * 面向stage\n    * shuffleMapStage\n    * resultStage\n  * DAG调度器会有轮循，不断的提交任务给任务调度器\n  \n  \n* TaskScheduler\n  * 面向task, 上面的stage就是任务task的集合\n  * 每个阶段形成对应的taskSet，提交给后台调度器\n  \n  \n* BackendScheduler\n  * 使用Nitty框架用rpc实现远程调用\n  * 通过Executor执行任务，最终在线程池中不断的执行任务\n  \n\nspark调动作最主要的一个方法应该是：\n  * runJob，\n  \n## 代码流程图如下：最好下载后观看\n![13-Spark流程图01.jpg](quiver-image-url/4C832AFE407E66E7F365D4BC63A36398.jpg =6742x5988)"
    },
    {
      "type": "markdown",
      "data": "![图画.png](quiver-image-url/B3CC21DEDC58597E06EB6F4069024669.png =1122x1197)"
    },
    {
      "type": "markdown",
      "data": "```text\n以下内容均是拷贝参考内容\n\nSpark核心API\n-----------------\n\t[SparkContext]\n\t\t连接到spark集群,入口点.\n\n\t[HadoopRDD]\n\t\t读取hadoop上的数据，\n\n\t[MapPartitionsRDD]\n\t\t针对父RDD的每个分区提供了函数构成的新类型RDD.\n\n\t[PairRDDFunctions]\n\t\t对偶RDD函数类。\n\t\t可用于KV类型RDD的附加函数。可以通过隐式转化得到.\n\n\t[ShuffleRDD]\n\t\t从Shuffle中计算结果的RDD.\n\n\t[RDD]\n\t\t是分区的集合.\n\t\t弹性分布式数据集.\n\t\t不可变的数据分区集合.\n\t\t基本操作(map filter , persist)\n\t\t\n\t\t分区列表\t\t\t\t\t//数据\n\t\t应用给每个切片的计算函数\t//行为\n\t\t到其他RDD的依赖列表\t\t\t//依赖关系\n\t\t(可选)针对kv类型RDD的分区类\n\t\t(可选)首选位置列表\n\t\n\t[DAGScheduler]\n\t\t高级调度器层面，实现按照阶段(stage),shuffle一次就是一个新的阶段stage.\n\t\t对每个JOB的各阶段计算有向无环图(DAG)，并且跟踪RDD和每个阶段的输出。\n\t\t找出最小调度运行作业,将Stage对象以TaskSet方式提交给底层的调度器。\n\t\t底层调度器实现TaskScheduler,进而在cluster上运行job.\n\t\tTaskSet已经包含了全部的单独的task，这些Task都能够基于cluster的数据进行\n\t\t正确运行。\n\n\t\tStage通过在需要shuffle的边界处将RDD打碎来创建Stage对象。\n\t\t具有'窄依赖'的RDD操作(比如map /filter)被管道化至一个taskset中.\n\t\t而具有shuffle依赖的操作则包含多个Stage(一个进行输出，另一个进行输入)\n\t\t最会，每个stage都有一个针对其他stage的shuffle依赖，可以计算多个操作。\n\t\n\t\tDag调度器检测首选位置来运行rask，通过基于当前的缓存状态，并传递给底层的\n\t\ttask调度器来实现。根据shuffle的输出是否丢失处理故障问题。\n\n\t\t不是由stage内因为丢失文件引发的故障有task调度处理。在取消整个stage之前，\n\t\ttask会进行少量次数的重试操作。\n\n\t\t为了容错，同一stage可能会运行多次，称之为\"attemp\",如果task调度器报告了一个故障(该\n\t\t故障是由于上一个stage丢失输出文件而导致的)DAG调度就会重新提交丢失的stage。这个通过\n\t\t具有 FetchFailed的CompletionEvent对象或者ExecutorLost进行检测的。\n\t\tDAG调度器会等待一段时间看其他节点或task是否失败，然后对丢失的stage重新提交taskset，\n\t\t计算丢失的task。\n\n\n\t\t术语介绍\n\t\t[job]\n\t\t\t提交给调度的顶层的工作项目，由ActiveJob表示。\n\t\t\t是Stage集合。\n\n\t\t[Stage]\n\t\t\t是task的集合，计算job中的中间结果。同一RDD的每个分区都会应用相同的计算函数。\n\t\t\t在shuffle的边界处进行隔离(因此引入了隔断，需要上一个stage完成后，才能得到output结果)\n\t\t\t有两种类型的stage:1)ResultStage，用于执行action动作的最终stage。2)ShuffleMapStage,\n\t\t\t对shuffle进行输出文件的写操作的。如果job重用了同一个rdd的话，stage通常可以跨越多个\n\t\t\tjob实现共享。\n\n\t\t\t并行任务的集合，都会计算同一函数。所有task有着同样的shuffle依赖，调度器运行的task DAG\n\t\t\t在shuffle边界处划分成不同阶段。调度器以拓扑顺序执行.\n\n\t\t\t每个stage可以shuffleMapStage,该阶段下输出是下一个stage的输入，也可以是resultStage,该阶段\n\t\t\ttask直接执行spark action。对于shuffleMapStage，需要跟踪每个输出分区所在的节点。\n\n\t\t\t每个stage都有FirstJobId,区分于首次提交的id\n\t\t\t\n\t\t\t[ShuffleMapStage]\n\t\t\t\t产生输出数据，在每次shuffle之前发生。内部含有shuffleDep字段,有相关字段记录产生多少输出\n\t\t\t\t以及多少输出可用。\n\t\t\t\tDAGScheduler.submitMapStage()方法可以单独提交ubmitMapStage().\n\n\t\t\t[ResultStage]\n\t\t\t\t该阶段在RDD的一些分区中应用函数来计算Action的结果。有些stage并不会在所有分区上执行。\n\t\t\t\t例如first(),lookup();\n\n\t\t[Task]\n\t\t\t单独的工作单元，每个发送给一台主机。\n\n\t\t[Cache tracking]\n\t\t\tDag调度器找出哪些RDD被缓存，避免不必要的重复计算，同时，也会记住哪些shuffleMap已经输出了\n\t\t\t结果，避免map端shuffle的重复处理。\n\n\t\t[Preferred locations]\n\t\t\tdag调度器根据rdd的中首选位置属性计算task在哪里运行。\n\n\t\t[Cleanup]\n\t\t\t运行的job如果完成就会清楚数据结构避免内存泄漏，主要是针对耗时应用。\n\n\t\t\n\t\t[ActiveJob]\n\t\t\t在Dag调度器中运行job。作业分为两种类型，1)result job，计算ResultStage来执行action.\n\t\t\t2)map-state job,为shuffleMapState结算计算输出结果以供下游stage使用。\n\t\t\t主要使用finalStage字段进行类型划分。\n\n\t\t\tjob只跟踪客户端提交的\"leaf\" stage，通过调用Dag调度器的submitjob或者submitMapStage()方法实现.\n\t\t\tjob类型引发之前stage的执行，而且多个job可以共享之前的stage。这些依赖关系由DAG调度器内部管理。\n\n\t\t[LiveListenerBus]\n\t\t\t异步传输spark监听事件到监听器事件集合中。\n\n\t\t[EventLoop]\n\t\t\t从caller接受事件，在单独的事件线程中处理所有事件，该类的唯一子类是DAGSchedulerEventProcessLoop。\n\n\t\t[LiveListenerBus]\n\t\t\t监听器总线，存放Spark监听器事件的队列。用于监控。\n\t\t\n\t\t[OutputCommitCoordinator]\n\t\t\t输出提交协调器.决定提交的输出是否进入hdfs。\n\n\t\t\n\t\t[TaskScheduler]\n\t\t\t底层的调度器，唯一实现TaskSchedulerImpl。可插拔，同Dag调度器接受task，发送给cluster，\n\t\t\t运行任务，失败重试，返回事件给DAG调度器。\n\t\t\n\t\t[TaskSchedulerImpl]\n\t\t\tTaskScheduler调度器的唯一实现，通过BackendScheduler(后台调度器)实现各种类型集群的任务调度。\n\t\t\n\n\t\t[SchedulerBackend]\n\t\t\t可插拔的后台调度系统，本地调度，mesos调度，。。。\n\t\t\t在任务调度器下方，\n\t\t\t实现有三种\n\t\t\t1.LocalSchedulerBackend\n\t\t\t\t本地后台调度器\n\t\t\t\t启动task.\n\t\t\t\n\t\t\t2.StandaloneSchedulerBackend\n\t\t\t\t独立后台调度器\n\n\t\t\t3.CoarseGrainedSchedulerBackend\n\t\t\t\t粗粒度后台调度器\n\n\t\t[Executor]\n\t\t\tspark程序执行者，通过线程池执行任务。\n\n\n```"
    }
  ]
}
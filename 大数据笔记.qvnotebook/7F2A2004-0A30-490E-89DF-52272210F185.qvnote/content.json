{
  "title": "13-Spark-0404-Spark持久化及依赖",
  "cells": [
    {
      "type": "markdown",
      "data": "## 1，持久化\n> 01, persist\n\n> 02, cache，这个就是persist的一种，模式是内存模式而已\n\n> 创建持久化： rdd2.persist(StorageLevel.MEMORY_ONLY)\n\n> 删除持久化： rdd2.unpersist()\n\n```\nRDD持久化\n------------------\n\t跨操作进行RDD的内存式存储。\n\t持久化RDD时，节点上的每个分区都会保存操内存中,以备在其他操作中进行重用。\n\t缓存技术是迭代式计算和交互式查询的重要工具。\n\t使用persist()和cache()进行rdd的持久化。\n\tcache()是persist()一种.\n\taction第一次计算时会发生persist().\n\tspark的cache是容错的，如果rdd的任何一个分区丢失了，都可以通过最初创建rdd的进行重新计算。\n\tpersist可以使用不同的存储级别进行持久化。\n\n\n\tMEMORY_ONLY\t\t\t//只在内存\n\tMEMORY_AND_DISK\n\tMEMORY_ONLY_SER\t\t//内存存储(串行化)\n\tMEMORY_AND_DISK_SER \n\tDISK_ONLY\t\t\t//硬盘\n\tMEMORY_ONLY_2\t\t//带有副本 \n\tMEMORY_AND_DISK_2\t//快速容错。\n\tOFF_HEAP \n\n```\n\n\n* 01, StorageLevel.MEMORY_ONLY\n```scala\npackage im.ivanl001.bigData.Spark.A07_PersistAndCache\nimport org.apache.spark.{SparkConf, SparkContext}\nimport org.apache.spark.api.java.JavaSparkContext\nimport org.apache.spark.storage.StorageLevel\n/*\n *\n * 这里演示以下persist的作用，persist虽然是持久化，但是这个持久化可不是持久化到磁盘，persist有模式到说法，可以指定内存模式，磁盘模式等等\n *\n */\nobject A0701_Persist_Memory {\n\n  def main(args: Array[String]): Unit = {\n\n    //创建Spark配置对象\n    val conf = new SparkConf()\n\n    //集群模式下下面两行不要\n    conf.setAppName(\"WordCountScala\")\n    //设置master属性\n    //conf.setMaster(\"spark://master:7077\")\n    conf.setMaster(\"local[2]\")//数字是本地模式下开启几个线程模拟多线程\n\n    //通过conf创建sc\n    val sc = new SparkContext(conf)\n\n    val rdd1 = sc.parallelize(1 to 10)\n\n    val rdd2 = rdd1.map(e => {\n      println(\"ivanl001:\" + e)\n      e\n    })\n\n    //需要先设置缓存才行哈，动作结束之后再设置缓存是无效的\n    //这里的cache就是persist的一种，只不过模式设置成了StorageLevel.MEMORY_ONLY\n    //rdd2.cache()\n    //下面的persist和上面的cache是等价的\n    rdd2.persist(StorageLevel.MEMORY_ONLY)\n\n    rdd2.reduce(_ + _)\n\n    //前面已经reduce一次，如果再次reduce的还还会重新重头开始计算，会打印出map中的那些打印的\n    //rdd2.reduce(_ + _)\n\n    //但是如果缓存一下就不会重新计算了,但是有一点需要注意一下：缓存需要在第一次动作之前缓存哈\n    //rdd2.cache()\n    rdd2.reduce(_ + _)\n    \n    //如果删除持久化，后面的这个聚合还是需要重新transform计算过程的\n    rdd2.unpersist()\n    rdd2.reduce(_ + _)\n  }\n}\n```\n\n* 01, StorageLevel.DISK_ONLY\n```scala\npackage im.ivanl001.bigData.Spark.A07_PersistAndCache\nimport org.apache.spark.storage.StorageLevel\nimport org.apache.spark.{SparkConf, SparkContext}\n/*\n *\n * 这里演示以下persist的作用，persist虽然是持久化，但是这个持久化可不是持久化到磁盘，persist有模式到说法，可以指定内存模式，磁盘模式等等\n *\n */\nobject A0702_Persist_Disk {\n\n  def main(args: Array[String]): Unit = {\n\n    //创建Spark配置对象\n    val conf = new SparkConf()\n\n    //集群模式下下面两行不要\n    conf.setAppName(\"WordCountScala\")\n    //设置master属性\n    //conf.setMaster(\"spark://master:7077\")\n    conf.setMaster(\"local[2]\")//数字是本地模式下开启几个线程模拟多线程\n\n    //通过conf创建sc\n    val sc = new SparkContext(conf)\n\n    val rdd1 = sc.parallelize(1 to 10)\n\n    val rdd2 = rdd1.map(e => {\n      println(\"ivanl001:\" + e)\n      e\n    })\n\n    //需要先设置缓存才行哈，动作结束之后再设置缓存是无效的\n    //这里的cache就是persist的一种，只不过模式设置成了StorageLevel.MEMORY_ONLY\n    //一般不建议单独磁盘持久化，这样成本会比较高，速度也不会快很多哈\n    rdd2.persist(StorageLevel.DISK_ONLY)\n\n    rdd2.reduce(_ + _)\n\n    //前面已经reduce一次，如果再次reduce的还还会重新重头开始计算，会打印出map中的那些打印的\n    //rdd2.reduce(_ + _)\n\n    //但是如果缓存一下就不会重新计算了,但是有一点需要注意一下：缓存需要在第一次动作之前缓存哈\n    rdd2.reduce(_ + _)\n    \n    //如果删除持久化，后面的这个聚合还是需要重新transform计算过程的\n    rdd2.unpersist()\n    rdd2.reduce(_ + _)\n  }\n}\n```"
    },
    {
      "type": "markdown",
      "data": "## 2, 宽窄依赖等\n\n```scala\nDependency:依赖\n-------------\n\tNarrowDependency:\t子RDD的每个分区依赖于父RDD的少量分区。\n\t\t |\n\t\t/ \\\n\t\t---\n\t\t |----\tOneToOneDependency\t\t//父子RDD之间的分区存在一对一关系。\n\t\t |----\tRangeDependency\t\t\t//父RDD的一个分区范围和子RDD存在一对一关系。\n\t\t |----\tOneToOneDependency\t\t//父子RDD之间的分区存在一对一关系。\n\n\tShuffleDependency\t\t\t\t\t//依赖，在shuffle阶段输出时的一种依赖。\n\t\n\tPruneDependency\t\t\t\t\t\t//在PartitionPruningRDD和其父RDD之间的依赖\n\t\t\t\t\t\t\t\t\t\t//子RDD包含了父RDD的分区子集。\n```"
    },
    {
      "type": "markdown",
      "data": "## 3, spark模式\n\n```java\n创建spark上下文\n---------------\n[本地模式,通过线程模拟]\n\t本地后台调度器\n\tspark local\n\tspark local[3]\t\t\t\t\t\t\t//3线程,模拟cluster集群\n\tspark local[*]\t\t\t\t\t\t\t//匹配cpu个数，\n\tspark local[3,2]\t\t\t\t\t\t//3:3个线程，2最多重试次数。\n\n\n[相当于伪分布式]\n\tStandaloneSchedulerBackend\n\tspark local-cluster[N, cores, memory]\t//模拟spark集群。\n\n[完全分布式]\n\tStandaloneSchedulerBackend\n\tspark spark://s201:7077\t\t\t\t\t//连接到spark集群上.\n```"
    }
  ]
}
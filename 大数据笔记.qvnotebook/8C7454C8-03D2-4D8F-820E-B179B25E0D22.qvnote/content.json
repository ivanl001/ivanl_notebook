{
  "title": "10-Storm-0202-storm的分区",
  "cells": [
    {
      "type": "markdown",
      "data": "01, storm上运行jar包：\n> storm jar /mnt/hgfs/ivanl001/Desktop/everything/Storm_test.jar im.ivanl001.bigData.Storm.A03_WordCount.WordCountApp\n----\n\n## 1， shuffle\n  *随机分组，具体可以参考im.ivanl001.bigData.Storm.A03_WordCount_01_shuffle_and_field包下wordcount案例，spout到WordCountSplitBolt是随机分组的*\n  * 只需要在app中指定为shuffle分组方式即可\n  ```java\n  builder.setBolt(\"wordCountSplitBolt\", new WordCountSplitBolt(), 3).shuffleGrouping(\"wordCountSpout\").setNumTasks(3);\n  ```\n  \n## 2，field\n  *根据字段分组,比较好理解，参考im.ivanl001.bigData.Storm.A03_WordCount_01_shuffle_and_field包下案例，WordCountSplitBolt到WordCountSumBolt是字段分组*\n  * 只需要在app中指定为field分组方式即可  \n  ```java\n  builder.setBolt(\"wordCountSumBolt\", new WordCountSumBolt(), 4).fieldsGrouping(\"wordCountSplitBolt\", new Fields(\"word\")).setNumTasks(4);\n  ```\n\n## 3，All Group\n  *类似广播，也就是每个节点(Bolt)都会收到这组消息，参考im.ivanl001.bigData.Storm.A03_WordCount_03_Allgrouping.WordCountApp*\n  \n  * 只需要在app中指定为allgroup分组方式即可\n  ```java\n  builder.setBolt(\"wordCountSplitBolt\", new WordCountSplitBolt(), 3).allGrouping(\"wordCountSpout\").setNumTasks(3);\n  ```\n  \n## 4，direct group\n  *只发送给指定的一个bolt*\n  \n* 01， 在app中需要设定direct分组方式\n  ```java\n  builder.setBolt(\"wordCountSplitBolt\", new WordCountSplitBolt(), 3).directGrouping(\"wordCountSpout\").setNumTasks(3);\n  ```\n  \n* 02, 在wordCountSpout类中需要指定direct发送方式\n\n  ```java\n  public void nextTuple() {\n\n      IMTrackerUtils.writeTo(this, \"WordCountSpout----nextTuple\", \"master\", 8880);\n  \n      System.out.println(\"---------------------------nextTuple----------------------------\");\n  \n      String line = words.get(random.nextInt(words.size()));\n      //如果用direct分组，那么这里就不能直接这样发送了\n      //collector.emit(new Values(line));\n  \n      int directToTaskId = -999;\n      //因为这里需要测试direct分组方式，所以这里先把taskId拿到，其实应该放在open中取的效率会好一些，不过测试无所谓了\n      Map<Integer, String> taskToComponent = context.getTaskToComponent();\n      for (Map.Entry<Integer, String> entry : taskToComponent.entrySet()) {\n          if (\"wordCountSplitBolt\".equals(entry.getValue())){\n              //这里就取第一个好了，如果有其他复杂的算法也可以在这里进行计算\n              directToTaskId = entry.getKey();\n              //注意：这里不能用return啊，一定要记住了！！！\n              break;\n          }\n      }\n      collector.emitDirect(directToTaskId, new Values(line));\n  \n      //这里为了防止发送太快，延迟一下, 已经限制数量了，这里无所谓了\n      /*try {\n          Thread.sleep(1000);\n      } catch (InterruptedException e) {\n          e.printStackTrace();\n      }*/\n    }\n  ```\n\n## 5, global group\n  *对目标target tasked进行排序，选择最小的taskId号进行发送tuple,类似于direct,可以是特殊的direct分组。相当于特殊的direct group方式*\n  * 只需要在app中指定为global group分组方式即可\n  ```java\n  builder.setBolt(\"wordCountSplitBolt\", new WordCountSplitBolt(), 3).globalGrouping(\"wordCountSpout\").setNumTasks(3);\n  ```\n  \n\n\n## 6, 自定义分组(重点学习一下)\n\n* 01，实现CustomStreamGrouping，自定义分组的类\n  ```java\n  package im.ivanl001.bigData.Storm.A03_WordCount_06_CustomGrouping;\n\n  import org.apache.storm.generated.GlobalStreamId;\n  import org.apache.storm.grouping.CustomStreamGrouping;\n  import org.apache.storm.task.WorkerTopologyContext;\n  \n  import java.util.ArrayList;\n  import java.util.List;\n  \n  /**\n   * #author      : ivanl001\n   * #creator     : 2018-11-20 19:31\n   * #description : 自定义分组\n   **/\n  public class IMCustomGrouping implements CustomStreamGrouping {\n  \n      private List<Integer> targetTasks;\n  \n      public void prepare(WorkerTopologyContext context, GlobalStreamId stream, List<Integer> targetTasks) {\n          this.targetTasks = targetTasks;\n      }\n  \n      public List<Integer> chooseTasks(int taskId, List<Object> values) {\n  \n          //我们这里自定义直接全部分到最后一个task中\n          List<Integer> choosedTasks = new ArrayList<Integer>();\n          choosedTasks.add(targetTasks.get(targetTasks.size() - 1));\n          return choosedTasks;\n      }\n  \n  }\n  ```\n* 02, 在app中指定自定义分组方式\n  ```java\n  package im.ivanl001.bigData.Storm.A03_WordCount_06_CustomGrouping;\n\n  import org.apache.storm.Config;\n  import org.apache.storm.StormSubmitter;\n  import org.apache.storm.generated.AlreadyAliveException;\n  import org.apache.storm.generated.AuthorizationException;\n  import org.apache.storm.generated.InvalidTopologyException;\n  import org.apache.storm.topology.TopologyBuilder;\n  \n  /**\n   * #author      : ivanl001\n   * #creator     : 2018-11-17 09:09\n   * #description : 单词统计app,自定义分组方式\n   **/\n  public class WordCountApp {\n  \n  \n      public static void main(String[] args) throws InterruptedException, InvalidTopologyException, AuthorizationException, AlreadyAliveException {\n  \n          Config config = new Config();\n          config.setDebug(false);\n          //这个是设置开启几个worker\n          config.setNumWorkers(2);\n  \n          TopologyBuilder builder = new TopologyBuilder();\n  \n          //parallelism_hint是设置并发的数量，比如下面spout设置成2,那么会开两个线程，跑3个任务，这个时候一个线程就必须同时跑两个任务，这其实不太好，所以并发数需要尽量大于任务数\n          builder.setSpout(\"wordCountSpout\", new WordCountSpout(), 2).setNumTasks(2);\n  \n          //这里定义自定义分组\n          builder.setBolt(\"wordCountSplitBolt\", new WordCountSplitBolt(), 3).customGrouping(\"wordCountSpout\", new IMCustomGrouping()).setNumTasks(3);\n  \n          //builder.setBolt(\"wordCountSumBolt\", new WordCountSumBolt(), 4).fieldsGrouping(\"wordCountSplitBolt\", new Fields(\"word\")).setNumTasks(4);\n  \n  \n          //这里用本地模式来测试分区模式，消息还是发送到master上的nc好了，懒得改了，一样看\n          /*LocalCluster localCluster = new LocalCluster();\n          localCluster.submitTopology(\"localWordCountCluster\", config, builder.createTopology());\n          Thread.sleep(10000);\n          localCluster.shutdown();*/\n  \n          //集群提交\n          StormSubmitter.submitTopology(\"wordCountCluster\", config, builder.createTopology());\n      }\n  }\n  ```\n\n\n---\n> 下面把教程中的总计拷贝在这里以供后面学习使用\n---\n\n```java\n分组策略\n---------------\n\t1.shuffle\n\t\t随机分组.\n\n\t2.field分组\n\t\t安装指定filed的key进行hash处理，\n\t\t相同的field，一定进入到同一bolt.\n\n\t\t该分组容易产生数据倾斜问题，通过使用二次聚合避免此类问题。\n\n\t3.使用二次聚合避免倾斜。\n\t\ta)App入口类\n\t\t[App.java]\n\t\t/**\n\t\t * App\n\t\t */\n\t\tpublic class App {\n\t\t\tpublic static void main(String[] args) throws Exception {\n\t\t\t\tTopologyBuilder builder = new TopologyBuilder();\n\t\t\t\t//设置Spout\n\t\t\t\tbuilder.setSpout(\"wcspout\", new WordCountSpout()).setNumTasks(2);\n\t\t\t\t//设置creator-Bolt\n\t\t\t\tbuilder.setBolt(\"split-bolt\", new SplitBolt(),3).shuffleGrouping(\"wcspout\").setNumTasks(3);\n\t\t\t\t//设置counter-Bolt\n\t\t\t\tbuilder.setBolt(\"counter-1\", new CountBolt(),3).shuffleGrouping(\"split-bolt\").setNumTasks(3);\n\t\t\t\tbuilder.setBolt(\"counter-2\", new CountBolt(),2).fieldsGrouping(\"counter-1\",new Fields(\"word\")).setNumTasks(2);\n\n\t\t\t\tConfig conf = new Config();\n\t\t\t\tconf.setNumWorkers(2);\n\t\t\t\tconf.setDebug(true);\n\n\t\t\t\t/**\n\t\t\t\t * 本地模式storm\n\t\t\t\t */\n\t\t\t\tLocalCluster cluster = new LocalCluster();\n\t\t\t\tcluster.submitTopology(\"wc\", conf, builder.createTopology());\n\t\t\t\t//Thread.sleep(20000);\n\t\t//        StormSubmitter.submitTopology(\"wordcount\", conf, builder.createTopology());\n\t\t\t\t//cluster.shutdown();\n\n\t\t\t}\n\t\t}\n\n\n\t\tb)聚合bolt\n\t\t[CountBolt.java]\n\t\tpackage com.it18zhang.stormdemo.group.shuffle;\n\n\t\timport com.it18zhang.stormdemo.util.Util;\n\t\timport org.apache.storm.task.OutputCollector;\n\t\timport org.apache.storm.task.TopologyContext;\n\t\timport org.apache.storm.topology.IRichBolt;\n\t\timport org.apache.storm.topology.OutputFieldsDeclarer;\n\t\timport org.apache.storm.tuple.Fields;\n\t\timport org.apache.storm.tuple.Tuple;\n\t\timport org.apache.storm.tuple.Values;\n\n\t\timport java.util.HashMap;\n\t\timport java.util.Map;\n\n\t\t/**\n\t\t * countbolt，使用二次聚合，解决数据倾斜问题。\n\t\t * 一次聚合和二次聚合使用field分组，完成数据的最终统计。\n\t\t * 一次聚合和上次split工作使用\n\t\t */\n\t\tpublic class CountBolt implements IRichBolt{\n\n\t\t\tprivate Map<String,Integer> map ;\n\n\t\t\tprivate TopologyContext context;\n\t\t\tprivate OutputCollector collector;\n\n\t\t\tprivate long lastEmitTime = 0 ;\n\n\t\t\tprivate long duration = 5000 ;\n\n\t\t\tpublic void prepare(Map stormConf, TopologyContext context, OutputCollector collector) {\n\t\t\t\tthis.context = context;\n\t\t\t\tthis.collector = collector;\n\t\t\t\tmap = new HashMap<String, Integer>();\n\t\t\t}\n\n\t\t\tpublic void execute(Tuple tuple) {\n\t\t\t\t//提取单词\n\t\t\t\tString word = tuple.getString(0);\n\t\t\t\tUtil.sendToLocalhost(this, word);\n\t\t\t\t//提取单词个数\n\t\t\t\tInteger count = tuple.getInteger(1);\n\t\t\t\tif(!map.containsKey(word)){\n\t\t\t\t\tmap.put(word, count);\n\t\t\t\t}\n\t\t\t\telse{\n\t\t\t\t\tmap.put(word,map.get(word) + count);\n\t\t\t\t}\n\t\t\t\t//判断是否符合清分的条件\n\t\t\t\tlong nowTime = System.currentTimeMillis() ;\n\t\t\t\tif ((nowTime - lastEmitTime) > duration) {\n\t\t\t\t\tfor (Map.Entry<String, Integer> entry : map.entrySet()) {\n\t\t\t\t\t\t//向下一环节发送数据\n\t\t\t\t\t\tcollector.emit(new Values(entry.getKey(), entry.getValue()));\n\t\t\t\t\t}\n\t\t\t\t\t//清空map\n\t\t\t\t\tmap.clear();\n\t\t\t\t\tlastEmitTime = nowTime ;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tpublic void cleanup() {\n\t\t\t\tfor(Map.Entry<String,Integer> entry : map.entrySet()){\n\t\t\t\t\tSystem.out.println(entry.getKey() + \" : \" + entry.getValue());\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tpublic void declareOutputFields(OutputFieldsDeclarer declarer) {\n\t\t\t\tdeclarer.declare(new Fields(\"word\",\"count\"));\n\n\t\t\t}\n\n\t\t\tpublic Map<String, Object> getComponentConfiguration() {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t3.all分组\n\t\t使用广播分组。\n\t\tbuilder.setBolt(\"split-bolt\", new SplitBolt(),2).allGrouping(\"wcspout\").setNumTasks(2);\n\n\t4.direct(特供)\n\t\t只发送给指定的一个bolt.\n\n\t\t//a.通过emitDirect()方法发送元组\n\t\t//可以通过context.getTaskToComponent()方法得到所有taskId和组件名的映射\n\t\tcollector.emitDirect(taskId,new Values(line));\n\t\t\n\t\t//b.指定directGrouping方式。\n\t\tbuilder.setBolt(\"split-bolt\", new SplitBolt(),2).directGrouping(\"wcspout\").setNumTasks(2);\n\n\t5.global分组\n\t\t对目标target tasked进行排序，选择最小的taskId号进行发送tuple\n\t\t类似于direct,可以是特殊的direct分组。\n\n\t6.自定义分组\n\t\ta)自定义CustomStreamGrouping类\n\t\t\t/**\n\t\t\t * 自定义分组\n\t\t\t */\n\t\t\tpublic class MyGrouping implements CustomStreamGrouping {\n\n\t\t\t\t//接受目标任务的id集合\n\t\t\t\tprivate List<Integer> targetTasks ;\n\n\t\t\t\tpublic void prepare(WorkerTopologyContext context, GlobalStreamId stream, List<Integer> targetTasks) {\n\t\t\t\t\tthis.targetTasks = targetTasks ;\n\t\t\t\t}\n\n\t\t\t\tpublic List<Integer> chooseTasks(int taskId, List<Object> values) {\n\t\t\t\t\tList<Integer> subTaskIds = new ArrayList<Integer>();\n\t\t\t\t\tfor(int i = 0 ; i <= targetTasks.size() / 2 ; i ++){\n\t\t\t\t\t\tsubTaskIds.add(targetTasks.get(i));\n\t\t\t\t\t}\n\t\t\t\t\treturn subTaskIds;\n\t\t\t\t}\n\t\t\t}\n\n\t\tb)设置分组策略\n\t\t\tpublic class App {\n\t\t\t\tpublic static void main(String[] args) throws Exception {\n\t\t\t\t\tTopologyBuilder builder = new TopologyBuilder();\n\t\t\t\t\t//设置Spout\n\t\t\t\t\tbuilder.setSpout(\"wcspout\", new WordCountSpout()).setNumTasks(2);\n\t\t\t\t\t//设置creator-Bolt\n\t\t\t\t\tbuilder.setBolt(\"split-bolt\", new SplitBolt(),4).customGrouping(\"wcspout\",new MyGrouping()).setNumTasks(4);\n\n\t\t\t\t\tConfig conf = new Config();\n\t\t\t\t\tconf.setNumWorkers(2);\n\t\t\t\t\tconf.setDebug(true);\n\n\t\t\t\t\t/**\n\t\t\t\t\t * 本地模式storm\n\t\t\t\t\t */\n\t\t\t\t\tLocalCluster cluster = new LocalCluster();\n\t\t\t\t\tcluster.submitTopology(\"wc\", conf, builder.createTopology());\n\t\t\t\t\tSystem.out.println(\"hello world\");\n\t\t\t\t}\n\t\t\t}\n\n\n\n```\n  "
    }
  ]
}
{
  "title": "15-eshop项目-0504-Hive数据清洗",
  "cells": [
    {
      "type": "markdown",
      "data": "*大概的意思是：创建hive表，然后把清洗后符合要求的数据放到指定的目录下，这个目录的规则需要符合分区的要求，然后动态的通过shell添加分区，自动的读取hdfs上的内容*\n"
    },
    {
      "type": "markdown",
      "data": "## hive数据库相关操作\n\n* 1, 创建数据库\n  > create database estore;\n\n* 2, 创建表\n  > create external table estore.logs01 (\nhostname string,\nremote_addr string,\nremote_user string,\ntime_local string,\nrequest string,\nstatus string,\nbody_bytes_sent string,\nhttp_referer string,\nhttp_user_agent string,\nhttp_x_forwarded_for string\n)\npartitioned by(year int ,month int,day int,hour int,minute int)\nrow format DELIMITED \nFIELDS TERMINATED BY ',' \nLINES TERMINATED BY '\\n'\nSTORED AS TEXTFILE;\n\n* 3, 添加分区\n  > alter table estore.logs01 add partition (year=2018, month=12, day=25, hour=17, minute=56);\n\n\n！！！！！！！有一点需要值得特别特别特别注意：添加分区的时候注意文件夹是没有0的，year=2018/month=12/day=25/hour=8/minute=12，这里只能是8，不能是08，如果想要直接存到对应的目录里，注意：一定不要存入到08目录下面了，要不然有的折腾！！！！！ \n"
    },
    {
      "type": "markdown",
      "data": "## 使用脚本添加hive分区\n\n* 1, 基础命令,这个是shell命令，不需要启动hive，在centos上可以直接运行\n  > hive -e \"alter table estore.logs add if not exists partition (year=2018, month=02, day=01, hour=13, minute=13) partition (year=2018, month=03, day=01, hour=13, minute=13)\"\n\n* 2, 定时任务(shell脚本内容)\n*hive_addPartition.sh, 加入到定时任务中，可以定时创建分区*\n  ```shell\n  #!/bin/bash\n  \n  # date -d \"+1 minute\" +%Y/%m/%d/%H:%M:%S\n  year=`date +%Y`\n  month=`date +%m`\n  day=`date +%d`\n  hour=`date +%H`\n  minute=`date +%M`\n  before_minute=`date -d \"-1 minute\" +%M`\n  after_minute=`date -d \"+1 minute\" +%M`\n  \n  echo $year-$month-$day $hour:$minute\n  echo '之前一分钟:'$before_minute\n  echo '之后一分钟:'$after_minute\n  \n  hive -e \"alter table estore.logs add if not exists partition (year=${year}, month=${month}, day=${day}, hour=${hour}, minute=${minute}) partition (year=${year}, month=${month}, day=${day}, hour=${hour}, minute=${before_minute}) partition (year=${year}, month=${month}, day=${day}, hour=${hour}, minute=${after_minute})\"\n  ```\n!!!!!!!注意：crontab -e中添加hive -e这样的脚本的时候，crontab的环境变量是有问题的，需要 把环境变量写入到脚本中才行哈：按照如下方式进行处理:\n```shell\n# 这个是crontab的脚本，也就是/var/spool/cron/root中的内容\nPATH=/sbin:/bin:/usr/sbin:/usr/bin:/usr/local/hive/bin:/usr/local/hadoop/bin:/usr/local/hadoop/sbin:/usr/local/hbase/bin\n\n* * * * * echo $PATH >> /data/ivanl001.txt\n* * * * * prepareLog.sh\n* * * * * hive_addPartition.sh\n```"
    },
    {
      "type": "markdown",
      "data": "load data inpath '/user/estore/cleaned/year=2018/month=12/day=25/hour=18/minute=11/master_done.log' into table logs01 partition (year=2018, month=12, day=25, hour=18, minute=11)"
    },
    {
      "type": "markdown",
      "data": ""
    },
    {
      "type": "markdown",
      "data": ""
    }
  ]
}
{
  "title": "07-HBase-0102-基本介绍和安装和集群搭建",
  "cells": [
    {
      "type": "markdown",
      "data": "## 1, Hbase的介绍\n* hadoop数据库，分布式可伸缩大型数据存储。\n* 用户对随机、实时读写数据。\n* 十亿行 x 百万列。\n* 版本化、非关系型数据库。\n* 存储机制：面向列存储，table是按row排序。\n\n* ![IMAGE](quiver-image-url/CB8485F4F5783DBE1CD17CF7650FF13F.jpg =1010x526)"
    },
    {
      "type": "markdown",
      "data": "## 2，Hbase集群搭建 \n* 01，和hdfs类似，HBase分主节点和区域节点,我们这里选择master和master01作为主节点，slave01, slave02, slave03作为区域节点\n\n* 02, 下载解压，配置环境变量这里就不再赘述\n\n* 03，如下命令验证安装版本\n  > hbase version\n\n* 04, 配置hbase的模式\n\n  * 0401, 本地模式, 就是配置一下hbase的本地存储目录就好了\n  \n    ```shell\n    \n    # hbase-env.sh中修改jkd的路径\n    EXPORT JAVA_HOME=/usr/local/jdk\n    \n    ```\n    \n      \n    ```xml\n    <!--hbase-site.xml指定文件存储路径-->\n    <property>\n  \t\t<name>hbase.rootdir</name>\n  \t\t<value>file://data/HBase/HFiles</value>\n  \t</property>\n    ```\n    \n  * 0402，伪分布模式\n  \n    ```shell\n    \n    # hbase-env.sh中修改jkd的路径\n    EXPORT JAVA_HOME=/usr/local/jdk\n    \n    ```\n    \n    ```xml\n    \n    <!--hbase-site.xml开启分布式并指定文件存储路径-->\n    # hbase-site.xml\n    <property>\n  \t\t<name>hbase.cluster.distributed</name>\n  \t\t<value>true</value>\n  \t</property>\n  \t<property>\n  \t\t<name>hbase.rootdir</name>\n  \t\t<value>hdfs://localhost:8030/hbase</value>\n  \t</property>\n    ```\n  * 0403, 完全分布式(上面两个就不做了，只做这一个)\n  \n\n    ```shell\n    \n    # hbase-env.sh中修改jkd的路径\n    export JAVA_HOME=/usr/local/jdk\n    \n    # hbase默认有自己的zk，这里应该是不用hbase自己的zk，而是用我们部署的那个zk\n    export HBASE_MANAGES_ZK=false\n    ```\n  \n    ```xml\n    \n    <!--hbase-site.xml开启分布式并指定文件存储路径-->\n    # hbase-site.xml\n    <property>\n  \t\t<name>hbase.cluster.distributed</name>\n  \t\t<value>true</value>\n  \t</property>\n  \t<!--指定hbase数据在hdfs上的存放路径-->\n  \t<property>\n  \t\t<name>hbase.rootdir</name>\n  \t\t<!--这里填写的是你想要的主服务器的地址，不能是集群nn的-->\n  \t\t<value>hdfs://master:8020/hbase</value>\n  \t</property>\n\t\t<!-- 配置zk地址 -->\n  \t<property>\n  \t\t<name>hbase.zookeeper.quorum</name>\n  \t\t<value>slave01:2181,slave02:2181,slave03:2181</value>\n  \t</property>\n  \t<!-- zk的本地目录 -->\n  \t<property>\n  \t\t<name>hbase.zookeeper.property.dataDir</name>\n  \t\t<value>/data/zookeeper</value>\n  \t</property>\n    ```\n    \n    *同时需要在config目录下的regionservers中添加hbase的数据服务器*\n    ```\n    slave01\n    slave02\n    slave03\n    ```\n    \n    *如果需要备用的主服务器，需要在regionservers相同的目录下，添加文件:backup-masters*\n    ```\n    master01\n    ```\n    \n* 05, 启动hbase, 最好在主服务器上启动\n  > start-hbase.sh\n\n* 06, 登陆hbase的webui\n  > http://master:16010"
    },
    {
      "type": "markdown",
      "data": "## 3, HBase与hdfs集群的融合\n*我们hdfs是需要结合zk进行容灾处理的， 比如我们的这个，有master和master01两台namenode的服务器， 任何一台挂掉，另外一台就必须从standby变为active活跃节点，那按照我们上面的hbase的集群是不能和这种集群hdfs完美的工作在一起的，因为我们已经指定了hbase.rootdir为master了，如果hdfs容灾之后， 这种设置就会让hbase出现问题，下面的配置可以让我们实现和容灾的hdfs的融合*\n\n* 01, 这里设置集群的nn，和上面的配置相比，其实只需改动hbase.rootdir\n  ```xml\n  <!--hbase-site.xml开启分布式并指定文件存储路径-->\n  # hbase-site.xml\n  <property>\n      <name>hbase.cluster.distributed</name>\n      <value>true</value>\n  </property>\n  <!--指定hbase数据在hdfs上的存放路径-->\n  <property>\n      <name>hbase.rootdir</name>\n      <!--这里填写的是集群nn的-->\n      <value>hdfs://imcluster:8020/hbase</value>\n  </property>\n      <!-- 配置zk地址 -->\n  <property>\n      <name>hbase.zookeeper.quorum</name>\n      <value>slave01:2181,slave02:2181,slave03:2181</value>\n  </property>\n  <!-- zk的本地目录 -->\n  <property>\n      <name>hbase.zookeeper.property.dataDir</name>\n      <value>/data/zookeeper</value>\n  </property>\n  ```\n  \n* 02，在hbase的根目录下创建一个hadoop的配置文件hdfs-site.xml的软连接，这里大家的具体命令可能不太一样，根据具体情况而定\n  > imcall.sh ln -s /usr/local/hadoop-2.7.5/etc/hadoop/hdfs-site.xml /usr/local/hbase-2.1.0/conf/hdfs-site.xml"
    }
  ]
}
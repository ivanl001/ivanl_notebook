{
  "title": "10-Storm-0211-Storm和Kafka的集成",
  "cells": [
    {
      "type": "markdown",
      "data": "## 1, Storm和kafka集成\n*注意：storm和kafka的集成不需要服务器上特别的配置，也即是代码层面的，从kafka中发送到storm里面即可*\n\n集成的时候总是在报错， 什么不能同步supervisor什么的，或者循环死掉了， log4j啥的问题，就是log4j需要单独指定， 然后版本也需要搭配，看pom.xml\n\n\n* 01, 首先配置pom.xml的依赖，注意：不能使用默认的log4j，会报错，需要单独指定，如下\n  ```xml\n  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n  <project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n           xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n           xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n      <modelVersion>4.0.0</modelVersion>\n  \n      <groupId>im.ivanl001</groupId>\n      <artifactId>10-Storm</artifactId>\n      <version>1.0-SNAPSHOT</version>\n  \n      <packaging>jar</packaging>\n  \n      <!--这他妈要求也太高了， 版本不对也不行，这怎么玩，要是升级了我怎么知道是哪个版本的？？？？？-->\n      <dependencies>\n          <dependency>\n              <groupId>org.apache.storm</groupId>\n              <artifactId>storm-core</artifactId>\n              <version>1.0.3</version>\n          </dependency>\n          <dependency>\n              <groupId>junit</groupId>\n              <artifactId>junit</artifactId>\n              <version>4.11</version>\n          </dependency>\n          <dependency>\n              <groupId>org.apache.storm</groupId>\n              <artifactId>storm-kafka</artifactId>\n              <version>1.0.2</version>\n          </dependency>\n          <dependency>\n              <groupId>log4j</groupId>\n              <artifactId>log4j</artifactId>\n              <version>1.2.17</version>\n          </dependency>\n          <dependency>\n              <groupId>org.apache.kafka</groupId>\n              <artifactId>kafka_2.10</artifactId>\n              <version>0.8.1.1</version>\n              <exclusions>\n                  <exclusion>\n                      <groupId>org.apache.zookeeper</groupId>\n                      <artifactId>zookeeper</artifactId>\n                  </exclusion>\n                  <exclusion>\n                      <groupId>log4j</groupId>\n                      <artifactId>log4j</artifactId>\n                  </exclusion>\n              </exclusions>\n          </dependency>\n  \n          <dependency>\n              <groupId>org.apache.storm</groupId>\n              <artifactId>storm-hbase</artifactId>\n              <version>1.0.3</version>\n          </dependency>\n  \n          <dependency>\n              <groupId>org.apache.hadoop</groupId>\n              <artifactId>hadoop-common</artifactId>\n              <version>2.7.3</version>\n          </dependency>\n  \n      </dependencies>\n  \n      <build>\n          <finalName>Storm_test</finalName>\n          <!--这个会输出包中的内容到这个文件夹-->\n          <!--<outputDirectory>/Users/ivanl001/Desktop/everything/</outputDirectory>-->\n          <!--这个会把打好的包放在下面这个文件夹-->\n          <directory>/Users/ivanl001/Desktop/everything/jar/</directory>\n      </build>\n  \n  \n  </project>\n  ```\n* 02, 需要配置kafka_spout, 这个是自带的，不需要自己重新写，如下：\n\n  ```java\n  package im.ivanl001.bigData.Storm.A06_Storm_Kafka;\n  \n  import org.apache.storm.Config;\n  import org.apache.storm.LocalCluster;\n  import org.apache.storm.StormSubmitter;\n  import org.apache.storm.generated.AlreadyAliveException;\n  import org.apache.storm.generated.AuthorizationException;\n  import org.apache.storm.generated.InvalidTopologyException;\n  import org.apache.storm.kafka.*;\n  import org.apache.storm.spout.SchemeAsMultiScheme;\n  import org.apache.storm.topology.TopologyBuilder;\n  \n  import java.util.UUID;\n  \n  /**\n   * #author      : ivanl001\n   * #creator     : 2018-11-17 09:09\n   * #description : 单词统计app, 和kafka的集成, 集成还有问题，先放着吧\n   **/\n  public class WordCountApp {\n  \n  \n      public static void main(String[] args) throws InterruptedException, InvalidTopologyException, AuthorizationException, AlreadyAliveException {\n  \n          Config config = new Config();\n          config.setDebug(false);\n          //这个是设置开启几个worker\n          config.setNumWorkers(1);\n  \n          TopologyBuilder builder = new TopologyBuilder();\n  \n          //这个是老api的写法，如果看官方文档可能和这个不太一样，但是使用的版本也是不一样的，需要适当的参考\n          String zkConnectString = \"slave01:2181\";\n          BrokerHosts hosts = new ZkHosts(zkConnectString);\n          //zkRoot不知道填写什么，先空着\n          SpoutConfig spoutConfig = new SpoutConfig(hosts, \"storm\", \"/storm\", UUID.randomUUID().toString());\n          spoutConfig.scheme = new SchemeAsMultiScheme(new StringScheme());\n          KafkaSpout kafkaSpout = new KafkaSpout(spoutConfig);\n  \n          //这里设置spout\n          builder.setSpout(\"kafka_spout\", kafkaSpout, 1).setNumTasks(1);\n  \n          //这里设置bolt\n          builder.setBolt(\"wordCountSplitBolt\", new WordCountSplitBolt(), 1).shuffleGrouping(\"kafka_spout\").setNumTasks(1);\n  \n          LocalCluster localCluster = new LocalCluster();\n          localCluster.submitTopology(\"localWordCountCluster\", config, builder.createTopology());\n          /*Thread.sleep(10000);\n          localCluster.shutdown();*/\n  \n          //集群提交\n          //StormSubmitter.submitTopology(\"wordCountCluster\", config, builder.createTopology());\n      }\n  }\n  \n  ```"
    }
  ]
}